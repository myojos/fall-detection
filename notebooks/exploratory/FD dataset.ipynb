{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\khale\\\\Documents\\\\OJOS'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(cd data/FD; bash ./doit.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"preprocessing\"):\n",
    "    os.mkdir(\"preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ojosfd/datasets/FallDetection.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ojosfd/datasets/FallDetection.py\n",
    "\n",
    "# system\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# common\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# opencv\n",
    "import cv2\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "SPLIT_RATIO = 0.8\n",
    "\n",
    "class FallDetectionDataset(Dataset):\n",
    "    \"\"\"FD Dataset\"\"\"\n",
    "    \n",
    "    # Standing: class 1, Sitting: class 2, Lying: class 3, Bending: class 4, Crawling: class 5, Empty: class 0\n",
    "    \n",
    "    def __init__(self, root_dir = 'data/FD/', transform=None, train=True, optical_flow=True,\n",
    "                 frames_per_clip=10, step_between_clips=1, verbose=False, resize=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            train (bool, optional): if ``True``, creates a dataset from the train split,\n",
    "                otherwise from the ``test`` split.\n",
    "            frames_per_clip (int): number of frames in a clip.\n",
    "            step_between_clips (int, optional): number of frames between each clip.\n",
    "        Returns:\n",
    "            video (Tensor[T, H, W, C]): the `T` video frames\n",
    "            label (int): class of the video clip\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.verbose = verbose\n",
    "        self.frames_per_clip = frames_per_clip\n",
    "        self.step_between_clips = step_between_clips\n",
    "        self.optical_flow = optical_flow\n",
    "        subdirs = [os.path.join(root_dir, item) for item in os.listdir(root_dir)\n",
    "                   if os.path.isdir(os.path.join(root_dir, item))]\n",
    "        \n",
    "        if train:\n",
    "            subdirs = subdirs[:int(len(subdirs)*SPLIT_RATIO)]\n",
    "        else:\n",
    "            subdirs = subdirs[int(len(subdirs)*SPLIT_RATIO):]\n",
    "        \n",
    "        self.video_clips = []\n",
    "        self.targets = []\n",
    "        for subdir in (subdirs):\n",
    "            if self.verbose:\n",
    "                print(\"[Dataset] reading folder: \", subdir)\n",
    "            labels = pd.read_csv(os.path.join(subdir, \"labels.csv\"))\n",
    "            labels.set_index('index', inplace=True)\n",
    "            labels.loc[labels['class'] > 5, 'class'] = 0\n",
    "            if resize:\n",
    "                self.__resize_imgs(subdir)\n",
    "            self.__create_optical_flow(subdir)\n",
    "            clips, targets = self.__get_video_clips__(subdir, labels, frames_per_clip, step_between_clips)\n",
    "            self.video_clips.extend(clips)\n",
    "            self.targets.extend(targets)\n",
    "    \n",
    "    def __resize_imgs(self, video_dir):\n",
    "        width, height=256, 256\n",
    "        images_dir = os.path.join(video_dir, \"rgb\")\n",
    "        image_files = [f for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
    "        if self.verbose:\n",
    "            print(\"[Dataset] resizing image files\")\n",
    "        for idx in tqdm(range(len(image_files)), disable=(not self.verbose)):\n",
    "            curr_frame = cv2.imread(os.path.join(images_dir, image_files[idx]))\n",
    "            curr_frame = cv2.resize(curr_frame, (width, height), interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(os.path.join(images_dir, image_files[idx]), curr_frame)\n",
    "    \n",
    "    def __create_optical_flow(self, video_dir):\n",
    "        model = cv2.optflow.createOptFlow_Farneback()\n",
    "        flows_dir = os.path.join(video_dir, \"flow\")\n",
    "        if not os.path.isdir(flows_dir):\n",
    "            os.mkdir(flows_dir)\n",
    "        images_dir = os.path.join(video_dir, \"rgb\")\n",
    "        image_files = [f for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
    "        prev_frame = None \n",
    "        prev_idx = -2\n",
    "        if self.verbose:\n",
    "            print(\"[Dataset] creating optical flows files\")\n",
    "        for idx in tqdm(range(1, len(image_files)), disable=(not self.verbose)):\n",
    "            file_name = os.path.join(flows_dir, image_files[idx][:-4] + \".npz\")\n",
    "            if not os.path.isfile(file_name):\n",
    "                if not prev_idx == idx-1:\n",
    "                    prev_frame = cv2.imread(os.path.join(images_dir, image_files[idx-1]), 0)\n",
    "                    prev_idx = idx - 1\n",
    "                curr_frame = cv2.imread(os.path.join(images_dir, image_files[idx]), 0)\n",
    "                flow = model.calc(prev_frame,curr_frame, None)\n",
    "                np.savez_compressed(file_name, arr=flow.astype(np.float16))\n",
    "                prev_frame, prev_idx = curr_frame, idx\n",
    "        model.collectGarbage()\n",
    "\n",
    "        \n",
    "    def __save_clip__(self, data_dir, idx, clip_flows, clip_img):\n",
    "        clip_dir = os.path.join(data_dir, \n",
    "                                \"clip_\" + str(self.frames_per_clip) + \"_\" + str(self.step_between_clips))\n",
    "        if not os.path.isdir(clip_dir):\n",
    "            os.mkdir(clip_dir)\n",
    "        clip_file = os.path.join(clip_dir, str(idx) + \".npz\")\n",
    "        if not os.path.isfile(clip_file):\n",
    "            flows = np.concatenate([np.load(file)['arr'] for file in clip_flows], axis=2)\n",
    "            np.savez_compressed(clip_file, flows)\n",
    "        clip_obj = {\n",
    "            \"flows\": clip_file,\n",
    "            \"img\": clip_img\n",
    "        }\n",
    "        return clip_obj\n",
    "        \n",
    "    def __get_video_clips__(self, data_dir, labels, frames_per_clip, step_between_clips=1):\n",
    "        clips = []\n",
    "        targets = []\n",
    "        flows_dir = os.path.join(data_dir, \"flow\")\n",
    "        imgs_dir = os.path.join(data_dir, \"rgb\")\n",
    "        imgs = [os.path.join(imgs_dir, f) for f in os.listdir(imgs_dir) \n",
    "                     if os.path.isfile(os.path.join(imgs_dir, f))]\n",
    "        flows = [os.path.join(flows_dir, f) for f in os.listdir(flows_dir) \n",
    "                     if os.path.isfile(os.path.join(flows_dir, f))]\n",
    "        if self.verbose:\n",
    "            print(\"[Dataset] creating video clips files\")\n",
    "        for idx in tqdm(range(0, len(imgs) - frames_per_clip, step_between_clips), disable=(not self.verbose)):\n",
    "            # slice clip frames\n",
    "            clip_flows = flows[idx:idx+frames_per_clip]\n",
    "            clip_img = imgs[idx]\n",
    "            clips.append(self.__save_clip__(data_dir, idx, clip_flows, clip_img))\n",
    "            # get majority label\n",
    "            indices = [int(f[-8:-4]) for f in clip_flows]\n",
    "            frame_labels = list(labels.loc[indices][\"class\"])\n",
    "            label = max(set(frame_labels), key = frame_labels.count)\n",
    "            targets.append(label)\n",
    "        return clips, targets\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.video_clips)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_file = self.video_clips[idx]\n",
    "        if self.optical_flow:\n",
    "            data = np.load(sample_file[\"flows\"])[\"arr_0\"].astype(np.float32)\n",
    "        else:\n",
    "            data = cv2.imread(sample_file[\"img\"])\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        target = self.targets[idx]\n",
    "        \n",
    "        return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ojosfd/datasets/FallDetection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ojosfd.utils import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] reading folder:  data/FD/1219\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61aa2cc52deb444c82cf091d7d006151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1219), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239c000cd4d64ee28f0ee52c91963b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1218), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5652dd5fce4823899754dfe1f568d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=121), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1260\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ccbf9792f640fca9e11352d577c32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1260), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e58d6a90f1a4c828f8e28c1f2dd6f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4237c5214d634f13b9ebb9c7a3cac407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1301\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f522d5dc7141adb06141dd6fcae1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1301), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6f96eb0cdf410e9e28df293ad20417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d101230973457b8502126dec493c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=130), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1378\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b104d674a40f42fa8e020dd66d606193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1378), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4989594dad5f445382a72c7ceb86ac7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1377), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a40942fa50494b9875a9d6a78e4dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=137), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1392\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75811c011e64d09b60713a288cb18a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1392), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1e0574742243c99632e9e2bffb1b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c4d1cc2b0e4ad496cbbf785b65b034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=139), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1790\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc216d625324d5281ff71b06250b99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1790), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a7dab0b7e64b9cbc58be0859944cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1789), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18d4d207efd4d23ad7c40a6be478b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=178), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1843\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff1c6bb40274ba2bab03dd0336fc1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1843), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe5a8833ec941fa87bb920dae2a3517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1842), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64acef918714351baabc0c2063affb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=184), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1954\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3b62041e3a4b8fa528ab3f108ea7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c913083171d44e9ea74ad1128ec28107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d04c6650f2d414f884d1a299bde2bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=195), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/2123\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a941944522149c6a83a2e6d7e75ba9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2123), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549bf16f166d49c1a5e5ab5be77e5d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831a98ceb97e44a3983cfe057b9bf980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=212), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/489\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae3abe8aedd4d6f9cc078126ba1d70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=489), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9298f8a921ff4478807085b8165e680b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=488), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a17eac975ad493a87ad7ef6c7fda3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/569\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db0aa90ceb1495a82cd545307f8a19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=569), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b9d4e6190346ffb8cea9672db7cf36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=568), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cc5baad08244f9b0789988af79142b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=56), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/581\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01df97c38c1a4bd9b7e6e314d1aaee3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=581), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67648543fb7549bab7306d891dc563f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=580), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3ff1165d194cb3906988b4e7d42e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/722\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a544f926c904fbc811ee612e743d320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=722), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e9d2858d004e62a30c3b14b3bff840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=721), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d086c12d89e940b48df34d2f833bc081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=72), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/731\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22985333305a41189f57126673509c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=731), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde71d80d18a401da8f7457fd1a6321c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=730), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3d7cf87e5842a7b085d4f574932c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=73), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/758\n",
      "[Dataset] resizing image files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b329b16f37c84437b8cb7d229acce836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=758), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating optical flows files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64222b5bfcad4da3863cfbef150fab56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=757), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] creating video clips files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4669ea7cb4b4a9db7e3a220798197a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=75), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'resize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-5dfed5265e0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n\u001b[1;32m---> 28\u001b[1;33m                                           shuffle=True, num_workers=0, resize=True)\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'resize'"
     ]
    }
   ],
   "source": [
    "# Example of using the dataset\n",
    "# Note using AlbuWrapperNumpy because the images are numpy array not PIL image\n",
    "\n",
    "transformations = transforms.Compose(\n",
    "    [AlbuWrapperNumpy(alb.Compose(\n",
    "        [\n",
    "            alb.RandomCrop(244, 244, always_apply=True),\n",
    "            aat.HorizontalFlip(),\n",
    "            aat.Cutout(2, 10, 10)\n",
    "        ])),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(0.5,0.5)])\n",
    "\n",
    "transformationsOF = transforms.Compose(\n",
    "    [AlbuWrapperNumpy(alb.Compose(\n",
    "        [\n",
    "            alb.RandomCrop(244, 244, always_apply=True),\n",
    "            transformers.HorizontalFlipOF(),\n",
    "            aat.Cutout(2, 10, 10)\n",
    "        ])),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(0.5,0.5)])\n",
    "\n",
    "train_dataset = FallDetectionDataset(train=True, optical_flow=False, step_between_clips=10, frames_per_clip=10,\n",
    "                                     verbose=True, transform=transformations, resize=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=0, resize=True)\n",
    "\n",
    "print(len(train_loader))\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(batch_idx, (data.shape, target.shape))\n",
    "    if batch_idx == 1:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train batches: \", len(train_loader))\n",
    "print(\"Train shape: \", next(iter(train_loader))[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
