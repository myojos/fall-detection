{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Windows\n",
    "!rd /s \"exps/exp1/logs\"\n",
    "# Linux\n",
    "# !rm -r exps/exp1/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2332), started 0:01:26 ago. (Use '!kill 2332' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-111ab5091de42403\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-111ab5091de42403\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir exps/exp1/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = torch.ones((64, 3, 32, 32))\n",
    "writer = SummaryWriter(log_dir=\"exps/exp1/logs/mobilenet_graph\")\n",
    "writer.add_graph(mobilenet, input_batch)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average input channels of conv layer and return new model\n",
    "def replace_conv(model, inplanes, outplanes=32):\n",
    "    conv_weights = list(model.parameters())[0].clone().detach().numpy()\n",
    "    new_conv_weights = conv_weights.mean(axis=1)\n",
    "    new_conv_weights = np.repeat(new_conv_weights[:, np.newaxis, :, :], inplanes, axis=1)\n",
    "    new_conv = torch.nn.Conv2d(inplanes, outplanes, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "    new_conv.weight = torch.nn.Parameter(torch.from_numpy(new_conv_weights))\n",
    "    model._modules['features'][0][0] = new_conv\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "mobilenet = replace_conv(mobilenet, 10)\n",
    "input_batch = torch.ones((64, 10, 32, 32))\n",
    "writer = SummaryWriter(log_dir=\"exps/exp1/logs/new_mobilenet_graph\")\n",
    "writer.add_graph(mobilenet, input_batch)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting exps/exp1/transforms.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile exps/exp1/transforms.py\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "import albumentations as alb\n",
    "import albumentations.augmentations.transforms as aat\n",
    "\n",
    "class AlbuWrapperNumpy:  # typing: ignore\n",
    "    def __init__(self, atrans: alb.BasicTransform):\n",
    "        self.atrans = atrans\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.atrans(image=img)[\"image\"]\n",
    "\n",
    "alb_transforms = alb.Compose(\n",
    "        [\n",
    "            alb.Resize(256, 256, always_apply=True),\n",
    "            alb.RandomCrop(244, 244, always_apply=True),\n",
    "                aat.HorizontalFlip(),\n",
    "            aat.Cutout(2, 10, 10)\n",
    "        ])\n",
    "alb_rescale = alb.Resize(244, 244, always_apply=True)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "  [transforms.ToTensor(),\n",
    "    transforms.Normalize(0.449, 0.226)])\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "  [AlbuWrapperNumpy(alb_rescale), transform])\n",
    "train_transforms = transforms.Compose(\n",
    "  [AlbuWrapperNumpy(alb_transforms), transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run exps/exp1/transforms.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] reading folder:  data/FD/1219\n",
      "[Dataset] Creating optical flow for folder:  data/FD/1219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4569fc391afa4def998fcadf2fb1fe8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1218), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1260\n",
      "[Dataset] Creating optical flow for folder:  data/FD/1260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e613895c996344558340d46a54189fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1301\n",
      "[Dataset] Creating optical flow for folder:  data/FD/1301\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492a5e478a69470f86855ff66146b3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1300), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1378\n",
      "[Dataset] Creating optical flow for folder:  data/FD/1378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da887804c4cd459fb5aa7c76b018ba99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1377), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1392\n",
      "[Dataset] Creating optical flow for folder:  data/FD/1392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabcb3a3da964e508d947c18afc67a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1790\n",
      "[Dataset] Creating optical flow for folder:  data/FD/1790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053343fe97314cc4b398a5a150a03627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1789), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1843\n",
      "[Dataset] Creating optical flow for folder:  data/FD/1843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bc10a745d7493681801fe59596d23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1842), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/1954\n",
      "[Dataset] Creating optical flow for folder:  data/FD/1954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63e0d399d8841cab0f7e82d98afd701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1953), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/2123\n",
      "[Dataset] Creating optical flow for folder:  data/FD/2123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d6a9d795d14d448c41f0fb1d001ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2122), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/489\n",
      "[Dataset] Creating optical flow for folder:  data/FD/489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ce05e71b544d4791cd8aa28edc458d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=488), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/569\n",
      "[Dataset] Creating optical flow for folder:  data/FD/569\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca8d18186eb44de84d919ee3bc07454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=568), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/581\n",
      "[Dataset] Creating optical flow for folder:  data/FD/581\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5c1dd1e86143fda0545161bf175f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=580), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/722\n",
      "[Dataset] Creating optical flow for folder:  data/FD/722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4811ba8c004b29972510781d3c9850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=721), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/731\n",
      "[Dataset] Creating optical flow for folder:  data/FD/731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc20b0d43ca4a0e8b198ce7d518bf80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=730), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/758\n",
      "[Dataset] Creating optical flow for folder:  data/FD/758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588841e6a81e46369d78d84b9ae967db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=757), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/786\n",
      "[Dataset] Creating optical flow for folder:  data/FD/786\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfc70763361411081f6ee87aa67023e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=785), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/807\n",
      "[Dataset] Creating optical flow for folder:  data/FD/807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48708cda6f6e4d1fabd74c5f8bb5ea9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=806), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/832\n",
      "[Dataset] Creating optical flow for folder:  data/FD/832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e819b08bc3104329894663415d85b25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=831), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataset] reading folder:  data/FD/925\n",
      "[Dataset] Creating optical flow for folder:  data/FD/925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a62bf1bfa94b8183f21e60d4b2256d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=924), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run preprocessing/FallDetectionDataset.py\n",
    "\n",
    "train_dataset = FallDetectionDataset(train=True, optical_flow=True, step_between_clips=10, transform=train_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, pin_memory = True,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = FallDetectionDataset(train=False, optical_flow=True, step_between_clips=10, transform=train_transforms)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32,  pin_memory = True,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "loss_function = torch.nn.modules.loss.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss_function, epoch, writer, device):\n",
    "    model = model.to(device)\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    writer.add_scalar(\"loss/train\", train_loss, global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_function, epoch, writer, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_function(output, target).sum().item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    writer.add_scalar(\"loss/test\", test_loss, global_step=epoch)\n",
    "    writer.add_scalar(\"accuracy\", accuracy, global_step=epoch)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, lr=0.1, epochs=5, start_epoch=0, device_name=\"cpu\"):\n",
    "    device = torch.device(device_name)\n",
    "    model = model.to(device)\n",
    "    writer = SummaryWriter(log_dir=f\"exps/exp1/logs/device{device_name}/lr{lr}/\")\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optim, 1, gamma=0.25)\n",
    "    accuracy = 0\n",
    "    tol = 0.005\n",
    "    no_advance = 0\n",
    "    print(\"Started training\")\n",
    "    for epoch in range(start_epoch, start_epoch + epochs):\n",
    "        train(model, train_loader, optim, loss_function, epoch, writer, device)\n",
    "        new_accuracy = test(model, test_loader, loss_function, epoch, writer, device)\n",
    "        no_advance = no_advance + 1 if new_accuracy - accuracy <= tol else 0\n",
    "        if no_advance >= 5:\n",
    "            break\n",
    "        accuracy = new_accuracy\n",
    "        scheduler.step()\n",
    "        print(\"Current LR: \", scheduler.get_lr())\n",
    "    writer.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(freeze=True, new_classifier=True, inplanes=10, pretrained=True, start_model=None):\n",
    "    model = start_model\n",
    "    if start_model is None:\n",
    "        model = models.mobilenet_v2(pretrained=pretrained)\n",
    "    start_freeze = 0\n",
    "    if new_classifier:\n",
    "        model = replace_conv(model, inplanes)\n",
    "        start_freeze = 1\n",
    "    for layer in model.features[start_freeze:]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = False\n",
    "    input_batch = torch.ones((64, inplanes, 32, 32))\n",
    "    writer = SummaryWriter(log_dir=\"exps/exp1/logs/model\")\n",
    "    writer.add_graph(model, input_batch)\n",
    "    writer.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training\n",
      "Train Epoch: 0 [0/1800 (0%)]\tLoss: 13.327008\n",
      "Train Epoch: 0 [160/1800 (9%)]\tLoss: 35.803833\n",
      "Train Epoch: 0 [320/1800 (18%)]\tLoss: 16.783487\n",
      "Train Epoch: 0 [480/1800 (26%)]\tLoss: 38.873627\n",
      "Train Epoch: 0 [640/1800 (35%)]\tLoss: 24.753510\n",
      "Train Epoch: 0 [800/1800 (44%)]\tLoss: 42.182766\n",
      "Train Epoch: 0 [960/1800 (53%)]\tLoss: 16.004786\n",
      "Train Epoch: 0 [1120/1800 (61%)]\tLoss: 6.237300\n",
      "Train Epoch: 0 [1280/1800 (70%)]\tLoss: 5.366728\n",
      "Train Epoch: 0 [1440/1800 (79%)]\tLoss: 7.472356\n",
      "Train Epoch: 0 [1600/1800 (88%)]\tLoss: 8.473408\n",
      "Train Epoch: 0 [1760/1800 (96%)]\tLoss: 4.223253\n",
      "\n",
      "Test set: Average loss: 0.1520, Accuracy: 226/333 (68%)\n",
      "\n",
      "Current LR:  [0.00625]\n",
      "Train Epoch: 1 [0/1800 (0%)]\tLoss: 4.421755\n",
      "Train Epoch: 1 [160/1800 (9%)]\tLoss: 3.202326\n",
      "Train Epoch: 1 [320/1800 (18%)]\tLoss: 2.657738\n",
      "Train Epoch: 1 [480/1800 (26%)]\tLoss: 7.726010\n",
      "Train Epoch: 1 [640/1800 (35%)]\tLoss: 2.231459\n",
      "Train Epoch: 1 [800/1800 (44%)]\tLoss: 3.444578\n",
      "Train Epoch: 1 [960/1800 (53%)]\tLoss: 1.239429\n",
      "Train Epoch: 1 [1120/1800 (61%)]\tLoss: 3.090885\n",
      "Train Epoch: 1 [1280/1800 (70%)]\tLoss: 2.988668\n",
      "Train Epoch: 1 [1440/1800 (79%)]\tLoss: 2.533676\n",
      "Train Epoch: 1 [1600/1800 (88%)]\tLoss: 3.116326\n",
      "Train Epoch: 1 [1760/1800 (96%)]\tLoss: 4.968369\n",
      "\n",
      "Test set: Average loss: 0.1182, Accuracy: 183/333 (55%)\n",
      "\n",
      "Current LR:  [0.0015625]\n",
      "Train Epoch: 2 [0/1800 (0%)]\tLoss: 1.465834\n",
      "Train Epoch: 2 [160/1800 (9%)]\tLoss: 3.044391\n",
      "Train Epoch: 2 [320/1800 (18%)]\tLoss: 3.841146\n",
      "Train Epoch: 2 [480/1800 (26%)]\tLoss: 1.724272\n",
      "Train Epoch: 2 [640/1800 (35%)]\tLoss: 0.713304\n",
      "Train Epoch: 2 [800/1800 (44%)]\tLoss: 3.890841\n",
      "Train Epoch: 2 [960/1800 (53%)]\tLoss: 3.253946\n",
      "Train Epoch: 2 [1120/1800 (61%)]\tLoss: 3.453136\n",
      "Train Epoch: 2 [1280/1800 (70%)]\tLoss: 1.564378\n",
      "Train Epoch: 2 [1440/1800 (79%)]\tLoss: 4.150604\n",
      "Train Epoch: 2 [1600/1800 (88%)]\tLoss: 2.538765\n",
      "Train Epoch: 2 [1760/1800 (96%)]\tLoss: 1.141709\n",
      "\n",
      "Test set: Average loss: 0.0705, Accuracy: 215/333 (65%)\n",
      "\n",
      "Current LR:  [0.000390625]\n",
      "Train Epoch: 3 [0/1800 (0%)]\tLoss: 3.142955\n",
      "Train Epoch: 3 [160/1800 (9%)]\tLoss: 1.460075\n",
      "Train Epoch: 3 [320/1800 (18%)]\tLoss: 0.856242\n",
      "Train Epoch: 3 [480/1800 (26%)]\tLoss: 1.825359\n",
      "Train Epoch: 3 [640/1800 (35%)]\tLoss: 1.193720\n",
      "Train Epoch: 3 [800/1800 (44%)]\tLoss: 2.277800\n",
      "Train Epoch: 3 [960/1800 (53%)]\tLoss: 1.899619\n",
      "Train Epoch: 3 [1120/1800 (61%)]\tLoss: 1.026734\n",
      "Train Epoch: 3 [1280/1800 (70%)]\tLoss: 1.593859\n",
      "Train Epoch: 3 [1440/1800 (79%)]\tLoss: 1.214786\n",
      "Train Epoch: 3 [1600/1800 (88%)]\tLoss: 1.289730\n",
      "Train Epoch: 3 [1760/1800 (96%)]\tLoss: 2.045899\n",
      "\n",
      "Test set: Average loss: 0.0688, Accuracy: 209/333 (63%)\n",
      "\n",
      "Current LR:  [9.765625e-05]\n",
      "Train Epoch: 4 [0/1800 (0%)]\tLoss: 1.435624\n",
      "Train Epoch: 4 [160/1800 (9%)]\tLoss: 2.444732\n",
      "Train Epoch: 4 [320/1800 (18%)]\tLoss: 3.377619\n",
      "Train Epoch: 4 [480/1800 (26%)]\tLoss: 0.755149\n",
      "Train Epoch: 4 [640/1800 (35%)]\tLoss: 2.042993\n",
      "Train Epoch: 4 [800/1800 (44%)]\tLoss: 1.697670\n",
      "Train Epoch: 4 [960/1800 (53%)]\tLoss: 2.217686\n",
      "Train Epoch: 4 [1120/1800 (61%)]\tLoss: 2.939342\n",
      "Train Epoch: 4 [1280/1800 (70%)]\tLoss: 2.678980\n",
      "Train Epoch: 4 [1440/1800 (79%)]\tLoss: 3.891634\n",
      "Train Epoch: 4 [1600/1800 (88%)]\tLoss: 1.363759\n",
      "Train Epoch: 4 [1760/1800 (96%)]\tLoss: 1.899344\n",
      "\n",
      "Test set: Average loss: 0.0647, Accuracy: 214/333 (64%)\n",
      "\n",
      "Current LR:  [2.44140625e-05]\n",
      "Train Epoch: 5 [0/1800 (0%)]\tLoss: 1.806233\n",
      "Train Epoch: 5 [160/1800 (9%)]\tLoss: 1.581405\n",
      "Train Epoch: 5 [320/1800 (18%)]\tLoss: 1.894427\n",
      "Train Epoch: 5 [480/1800 (26%)]\tLoss: 1.474595\n",
      "Train Epoch: 5 [640/1800 (35%)]\tLoss: 2.108381\n",
      "Train Epoch: 5 [800/1800 (44%)]\tLoss: 2.470119\n",
      "Train Epoch: 5 [960/1800 (53%)]\tLoss: 1.733832\n",
      "Train Epoch: 5 [1120/1800 (61%)]\tLoss: 2.574795\n",
      "Train Epoch: 5 [1280/1800 (70%)]\tLoss: 1.228584\n",
      "Train Epoch: 5 [1440/1800 (79%)]\tLoss: 0.702410\n",
      "Train Epoch: 5 [1600/1800 (88%)]\tLoss: 2.025198\n",
      "Train Epoch: 5 [1760/1800 (96%)]\tLoss: 2.597893\n",
      "\n",
      "Test set: Average loss: 0.0642, Accuracy: 208/333 (62%)\n",
      "\n",
      "Current LR:  [6.103515625e-06]\n",
      "Train Epoch: 6 [0/1800 (0%)]\tLoss: 1.900399\n",
      "Train Epoch: 6 [160/1800 (9%)]\tLoss: 1.535454\n",
      "Train Epoch: 6 [320/1800 (18%)]\tLoss: 1.610861\n",
      "Train Epoch: 6 [480/1800 (26%)]\tLoss: 1.264772\n",
      "Train Epoch: 6 [640/1800 (35%)]\tLoss: 1.990161\n",
      "Train Epoch: 6 [800/1800 (44%)]\tLoss: 2.183219\n",
      "Train Epoch: 6 [960/1800 (53%)]\tLoss: 2.279717\n",
      "Train Epoch: 6 [1120/1800 (61%)]\tLoss: 1.691220\n",
      "Train Epoch: 6 [1280/1800 (70%)]\tLoss: 2.040849\n",
      "Train Epoch: 6 [1440/1800 (79%)]\tLoss: 2.292029\n",
      "Train Epoch: 6 [1600/1800 (88%)]\tLoss: 2.112798\n",
      "Train Epoch: 6 [1760/1800 (96%)]\tLoss: 1.004756\n",
      "\n",
      "Test set: Average loss: 0.0594, Accuracy: 223/333 (67%)\n",
      "\n",
      "Current LR:  [1.52587890625e-06]\n",
      "Train Epoch: 7 [0/1800 (0%)]\tLoss: 2.900438\n",
      "Train Epoch: 7 [160/1800 (9%)]\tLoss: 2.374521\n",
      "Train Epoch: 7 [320/1800 (18%)]\tLoss: 3.611341\n",
      "Train Epoch: 7 [480/1800 (26%)]\tLoss: 2.219669\n",
      "Train Epoch: 7 [640/1800 (35%)]\tLoss: 0.860242\n",
      "Train Epoch: 7 [800/1800 (44%)]\tLoss: 1.794416\n",
      "Train Epoch: 7 [960/1800 (53%)]\tLoss: 1.308500\n",
      "Train Epoch: 7 [1120/1800 (61%)]\tLoss: 1.454349\n",
      "Train Epoch: 7 [1280/1800 (70%)]\tLoss: 2.028714\n",
      "Train Epoch: 7 [1440/1800 (79%)]\tLoss: 2.319695\n",
      "Train Epoch: 7 [1600/1800 (88%)]\tLoss: 1.397054\n",
      "Train Epoch: 7 [1760/1800 (96%)]\tLoss: 1.860769\n",
      "\n",
      "Test set: Average loss: 0.0621, Accuracy: 223/333 (67%)\n",
      "\n",
      "Current LR:  [3.814697265625e-07]\n",
      "Train Epoch: 8 [0/1800 (0%)]\tLoss: 2.815400\n",
      "Train Epoch: 8 [160/1800 (9%)]\tLoss: 1.723287\n",
      "Train Epoch: 8 [320/1800 (18%)]\tLoss: 0.799338\n",
      "Train Epoch: 8 [480/1800 (26%)]\tLoss: 2.154335\n",
      "Train Epoch: 8 [640/1800 (35%)]\tLoss: 2.500303\n",
      "Train Epoch: 8 [800/1800 (44%)]\tLoss: 1.596773\n",
      "Train Epoch: 8 [960/1800 (53%)]\tLoss: 1.445750\n",
      "Train Epoch: 8 [1120/1800 (61%)]\tLoss: 2.854648\n",
      "Train Epoch: 8 [1280/1800 (70%)]\tLoss: 1.918529\n",
      "Train Epoch: 8 [1440/1800 (79%)]\tLoss: 1.543335\n",
      "Train Epoch: 8 [1600/1800 (88%)]\tLoss: 1.397152\n",
      "Train Epoch: 8 [1760/1800 (96%)]\tLoss: 2.563866\n",
      "\n",
      "Test set: Average loss: 0.0700, Accuracy: 210/333 (63%)\n",
      "\n",
      "Current LR:  [9.5367431640625e-08]\n",
      "Train Epoch: 9 [0/1800 (0%)]\tLoss: 1.581380\n",
      "Train Epoch: 9 [160/1800 (9%)]\tLoss: 0.546471\n",
      "Train Epoch: 9 [320/1800 (18%)]\tLoss: 3.327093\n",
      "Train Epoch: 9 [480/1800 (26%)]\tLoss: 1.345455\n",
      "Train Epoch: 9 [640/1800 (35%)]\tLoss: 2.051838\n",
      "Train Epoch: 9 [800/1800 (44%)]\tLoss: 1.330862\n",
      "Train Epoch: 9 [960/1800 (53%)]\tLoss: 2.523060\n",
      "Train Epoch: 9 [1120/1800 (61%)]\tLoss: 2.917401\n",
      "Train Epoch: 9 [1280/1800 (70%)]\tLoss: 0.424134\n",
      "Train Epoch: 9 [1440/1800 (79%)]\tLoss: 1.291040\n",
      "Train Epoch: 9 [1600/1800 (88%)]\tLoss: 2.863611\n",
      "Train Epoch: 9 [1760/1800 (96%)]\tLoss: 0.555995\n",
      "\n",
      "Test set: Average loss: 0.0630, Accuracy: 220/333 (66%)\n",
      "\n",
      "Current LR:  [2.384185791015625e-08]\n",
      "Train Epoch: 10 [0/1800 (0%)]\tLoss: 1.506371\n",
      "Train Epoch: 10 [160/1800 (9%)]\tLoss: 1.831789\n",
      "Train Epoch: 10 [320/1800 (18%)]\tLoss: 1.092332\n",
      "Train Epoch: 10 [480/1800 (26%)]\tLoss: 1.711423\n",
      "Train Epoch: 10 [640/1800 (35%)]\tLoss: 2.751441\n",
      "Train Epoch: 10 [800/1800 (44%)]\tLoss: 2.303350\n",
      "Train Epoch: 10 [960/1800 (53%)]\tLoss: 1.931699\n",
      "Train Epoch: 10 [1120/1800 (61%)]\tLoss: 1.384079\n",
      "Train Epoch: 10 [1280/1800 (70%)]\tLoss: 1.366506\n",
      "Train Epoch: 10 [1440/1800 (79%)]\tLoss: 1.435984\n",
      "Train Epoch: 10 [1600/1800 (88%)]\tLoss: 3.123286\n",
      "Train Epoch: 10 [1760/1800 (96%)]\tLoss: 1.667627\n",
      "\n",
      "Test set: Average loss: 0.0644, Accuracy: 212/333 (64%)\n",
      "\n",
      "Current LR:  [5.960464477539063e-09]\n",
      "Train Epoch: 11 [0/1800 (0%)]\tLoss: 2.088892\n",
      "Train Epoch: 11 [160/1800 (9%)]\tLoss: 0.604465\n",
      "Train Epoch: 11 [320/1800 (18%)]\tLoss: 2.020609\n",
      "Train Epoch: 11 [480/1800 (26%)]\tLoss: 1.311609\n",
      "Train Epoch: 11 [640/1800 (35%)]\tLoss: 0.975653\n",
      "Train Epoch: 11 [800/1800 (44%)]\tLoss: 2.857175\n",
      "Train Epoch: 11 [960/1800 (53%)]\tLoss: 2.802753\n",
      "Train Epoch: 11 [1120/1800 (61%)]\tLoss: 1.827643\n",
      "Train Epoch: 11 [1280/1800 (70%)]\tLoss: 2.093961\n",
      "Train Epoch: 11 [1440/1800 (79%)]\tLoss: 3.292830\n",
      "Train Epoch: 11 [1600/1800 (88%)]\tLoss: 2.539564\n",
      "Train Epoch: 11 [1760/1800 (96%)]\tLoss: 1.986808\n",
      "\n",
      "Test set: Average loss: 0.0680, Accuracy: 202/333 (61%)\n",
      "\n",
      "Current LR:  [1.4901161193847657e-09]\n",
      "Train Epoch: 12 [0/1800 (0%)]\tLoss: 1.689684\n",
      "Train Epoch: 12 [160/1800 (9%)]\tLoss: 1.180233\n",
      "Train Epoch: 12 [320/1800 (18%)]\tLoss: 1.237992\n",
      "Train Epoch: 12 [480/1800 (26%)]\tLoss: 1.292921\n",
      "Train Epoch: 12 [640/1800 (35%)]\tLoss: 1.646482\n",
      "Train Epoch: 12 [800/1800 (44%)]\tLoss: 2.087509\n",
      "Train Epoch: 12 [960/1800 (53%)]\tLoss: 3.115623\n",
      "Train Epoch: 12 [1120/1800 (61%)]\tLoss: 0.839591\n",
      "Train Epoch: 12 [1280/1800 (70%)]\tLoss: 1.792897\n",
      "Train Epoch: 12 [1440/1800 (79%)]\tLoss: 1.369944\n",
      "Train Epoch: 12 [1600/1800 (88%)]\tLoss: 1.368371\n",
      "Train Epoch: 12 [1760/1800 (96%)]\tLoss: 0.638108\n",
      "\n",
      "Test set: Average loss: 0.0664, Accuracy: 209/333 (63%)\n",
      "\n",
      "Current LR:  [3.7252902984619143e-10]\n",
      "Train Epoch: 13 [0/1800 (0%)]\tLoss: 1.184745\n",
      "Train Epoch: 13 [160/1800 (9%)]\tLoss: 2.534611\n",
      "Train Epoch: 13 [320/1800 (18%)]\tLoss: 1.291986\n",
      "Train Epoch: 13 [480/1800 (26%)]\tLoss: 1.731483\n",
      "Train Epoch: 13 [640/1800 (35%)]\tLoss: 1.339490\n",
      "Train Epoch: 13 [800/1800 (44%)]\tLoss: 3.153255\n",
      "Train Epoch: 13 [960/1800 (53%)]\tLoss: 1.306653\n",
      "Train Epoch: 13 [1120/1800 (61%)]\tLoss: 0.994937\n",
      "Train Epoch: 13 [1280/1800 (70%)]\tLoss: 3.453037\n",
      "Train Epoch: 13 [1440/1800 (79%)]\tLoss: 1.590976\n",
      "Train Epoch: 13 [1600/1800 (88%)]\tLoss: 1.330027\n",
      "Train Epoch: 13 [1760/1800 (96%)]\tLoss: 2.096513\n",
      "\n",
      "Test set: Average loss: 0.0656, Accuracy: 220/333 (66%)\n",
      "\n",
      "Current LR:  [9.313225746154786e-11]\n",
      "Train Epoch: 14 [0/1800 (0%)]\tLoss: 0.912031\n",
      "Train Epoch: 14 [160/1800 (9%)]\tLoss: 1.762254\n",
      "Train Epoch: 14 [320/1800 (18%)]\tLoss: 1.455244\n",
      "Train Epoch: 14 [480/1800 (26%)]\tLoss: 1.640860\n",
      "Train Epoch: 14 [640/1800 (35%)]\tLoss: 2.181474\n",
      "Train Epoch: 14 [800/1800 (44%)]\tLoss: 1.824977\n",
      "Train Epoch: 14 [960/1800 (53%)]\tLoss: 2.051636\n",
      "Train Epoch: 14 [1120/1800 (61%)]\tLoss: 2.706641\n",
      "Train Epoch: 14 [1280/1800 (70%)]\tLoss: 2.726069\n",
      "Train Epoch: 14 [1440/1800 (79%)]\tLoss: 1.942785\n",
      "Train Epoch: 14 [1600/1800 (88%)]\tLoss: 1.503479\n",
      "Train Epoch: 14 [1760/1800 (96%)]\tLoss: 1.458787\n",
      "\n",
      "Test set: Average loss: 0.0723, Accuracy: 203/333 (61%)\n",
      "\n",
      "Current LR:  [2.3283064365386964e-11]\n",
      "Train Epoch: 15 [0/1800 (0%)]\tLoss: 3.120685\n",
      "Train Epoch: 15 [160/1800 (9%)]\tLoss: 0.955001\n",
      "Train Epoch: 15 [320/1800 (18%)]\tLoss: 0.485521\n",
      "Train Epoch: 15 [480/1800 (26%)]\tLoss: 1.910121\n",
      "Train Epoch: 15 [640/1800 (35%)]\tLoss: 2.617650\n",
      "Train Epoch: 15 [800/1800 (44%)]\tLoss: 1.163408\n",
      "Train Epoch: 15 [960/1800 (53%)]\tLoss: 1.386703\n",
      "Train Epoch: 15 [1120/1800 (61%)]\tLoss: 1.851517\n",
      "Train Epoch: 15 [1280/1800 (70%)]\tLoss: 1.513115\n",
      "Train Epoch: 15 [1440/1800 (79%)]\tLoss: 1.950572\n",
      "Train Epoch: 15 [1600/1800 (88%)]\tLoss: 2.375250\n",
      "Train Epoch: 15 [1760/1800 (96%)]\tLoss: 1.757407\n",
      "\n",
      "Test set: Average loss: 0.0615, Accuracy: 222/333 (67%)\n",
      "\n",
      "Current LR:  [5.820766091346741e-12]\n",
      "Train Epoch: 16 [0/1800 (0%)]\tLoss: 2.464233\n",
      "Train Epoch: 16 [160/1800 (9%)]\tLoss: 2.356148\n",
      "Train Epoch: 16 [320/1800 (18%)]\tLoss: 1.608090\n",
      "Train Epoch: 16 [480/1800 (26%)]\tLoss: 1.977448\n",
      "Train Epoch: 16 [640/1800 (35%)]\tLoss: 1.956244\n",
      "Train Epoch: 16 [800/1800 (44%)]\tLoss: 2.803783\n",
      "Train Epoch: 16 [960/1800 (53%)]\tLoss: 2.652627\n",
      "Train Epoch: 16 [1120/1800 (61%)]\tLoss: 2.460609\n",
      "Train Epoch: 16 [1280/1800 (70%)]\tLoss: 1.898872\n",
      "Train Epoch: 16 [1440/1800 (79%)]\tLoss: 1.519405\n",
      "Train Epoch: 16 [1600/1800 (88%)]\tLoss: 1.298661\n",
      "Train Epoch: 16 [1760/1800 (96%)]\tLoss: 0.929353\n",
      "\n",
      "Test set: Average loss: 0.0690, Accuracy: 209/333 (63%)\n",
      "\n",
      "Current LR:  [1.4551915228366853e-12]\n",
      "Train Epoch: 17 [0/1800 (0%)]\tLoss: 1.450937\n",
      "Train Epoch: 17 [160/1800 (9%)]\tLoss: 1.339474\n",
      "Train Epoch: 17 [320/1800 (18%)]\tLoss: 2.746630\n",
      "Train Epoch: 17 [480/1800 (26%)]\tLoss: 1.143040\n",
      "Train Epoch: 17 [640/1800 (35%)]\tLoss: 3.539622\n",
      "Train Epoch: 17 [800/1800 (44%)]\tLoss: 2.017386\n",
      "Train Epoch: 17 [960/1800 (53%)]\tLoss: 1.765798\n",
      "Train Epoch: 17 [1120/1800 (61%)]\tLoss: 2.907509\n",
      "Train Epoch: 17 [1280/1800 (70%)]\tLoss: 2.035108\n",
      "Train Epoch: 17 [1440/1800 (79%)]\tLoss: 1.409584\n",
      "Train Epoch: 17 [1600/1800 (88%)]\tLoss: 2.403670\n",
      "Train Epoch: 17 [1760/1800 (96%)]\tLoss: 2.411169\n",
      "\n",
      "Test set: Average loss: 0.0610, Accuracy: 205/333 (62%)\n",
      "\n",
      "Current LR:  [3.637978807091713e-13]\n",
      "Train Epoch: 18 [0/1800 (0%)]\tLoss: 1.725417\n",
      "Train Epoch: 18 [160/1800 (9%)]\tLoss: 2.412060\n",
      "Train Epoch: 18 [320/1800 (18%)]\tLoss: 2.205786\n",
      "Train Epoch: 18 [480/1800 (26%)]\tLoss: 3.020462\n",
      "Train Epoch: 18 [640/1800 (35%)]\tLoss: 1.983364\n",
      "Train Epoch: 18 [800/1800 (44%)]\tLoss: 1.638754\n",
      "Train Epoch: 18 [960/1800 (53%)]\tLoss: 2.209845\n",
      "Train Epoch: 18 [1120/1800 (61%)]\tLoss: 2.563610\n",
      "Train Epoch: 18 [1280/1800 (70%)]\tLoss: 1.017206\n",
      "Train Epoch: 18 [1440/1800 (79%)]\tLoss: 1.830078\n",
      "Train Epoch: 18 [1600/1800 (88%)]\tLoss: 0.658368\n",
      "Train Epoch: 18 [1760/1800 (96%)]\tLoss: 1.552968\n",
      "\n",
      "Test set: Average loss: 0.0647, Accuracy: 208/333 (62%)\n",
      "\n",
      "Current LR:  [9.094947017729283e-14]\n",
      "Train Epoch: 19 [0/1800 (0%)]\tLoss: 2.110435\n",
      "Train Epoch: 19 [160/1800 (9%)]\tLoss: 0.894825\n",
      "Train Epoch: 19 [320/1800 (18%)]\tLoss: 3.210529\n",
      "Train Epoch: 19 [480/1800 (26%)]\tLoss: 1.269558\n",
      "Train Epoch: 19 [640/1800 (35%)]\tLoss: 1.257121\n",
      "Train Epoch: 19 [800/1800 (44%)]\tLoss: 2.976613\n",
      "Train Epoch: 19 [960/1800 (53%)]\tLoss: 2.149854\n",
      "Train Epoch: 19 [1120/1800 (61%)]\tLoss: 0.763115\n",
      "Train Epoch: 19 [1280/1800 (70%)]\tLoss: 1.975181\n",
      "Train Epoch: 19 [1440/1800 (79%)]\tLoss: 1.299735\n",
      "Train Epoch: 19 [1600/1800 (88%)]\tLoss: 1.874671\n",
      "Train Epoch: 19 [1760/1800 (96%)]\tLoss: 1.996944\n",
      "\n",
      "Test set: Average loss: 0.0670, Accuracy: 208/333 (62%)\n",
      "\n",
      "Current LR:  [2.2737367544323207e-14]\n",
      "Wall time: 1h 27min 37s\n"
     ]
    }
   ],
   "source": [
    "PATH = \"exps/exp1/model.pth\"\n",
    "model = get_model(inplanes=20)\n",
    "if os.path.isfile(PATH):\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "%time train_model(model, epochs=20, device_name=\"cuda\")\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0663, Accuracy: 214/333 (64%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=\"exps/exp1/logs/model\")\n",
    "new_accuracy = test(model, test_loader, loss_function, 20, writer, device=\"cuda\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0641, Accuracy: 215/333 (65%)\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
